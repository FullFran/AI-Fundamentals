---
title: "El Modelo de Ising y el Paisaje de Energ칤a"
order: 6
description: "De la f칤sica de espines al Hamiltoniano de las Redes de Hopfield"
---

# 丘勇 El Modelo de Ising y el Paisaje de Energ칤a

Para entender por qu칠 una red neuronal puede "recordar" algo, primero tenemos que mirar c칩mo se comporta la materia. En f칤sica, el **Modelo de Ising** nos ense침a c칩mo peque침as unidades individuales (espines) pueden ponerse de acuerdo para crear un estado colectivo.

Es exactamente lo mismo que ocurre en una red neuronal: las neuronas son como espines que buscan un estado de equilibrio.

## 1. El Modelo de Ising: El Orden nace del Caos

Imagina una cuadr칤cula de 치tomos. Cada 치tomo tiene un "esp칤n" **s** que puede apuntar hacia arriba (+1) o hacia abajo (-1). 
- Si dos 치tomos vecinos apuntan al mismo lado, la energ칤a del sistema baja (estabilidad).
- Si apuntan a lados opuestos, la energ칤a sube (inestabilidad).

<math-block>
  E = - Sum( J_ij * s_i * s_j )
</math-block>

Donde **J_ij** es la fuerza de la relaci칩n entre el 치tomo **i** y el **j**. Ya te digo yo que esta f칩rmula es el tatarabuelo de la funci칩n de coste de cualquier red moderna.

## 2. La Conexi칩n con Hopfield

John Hopfield se dio cuenta de algo brillante: si tratamos a las neuronas como espines de Ising, podemos "programar" las conexiones **J_ij** (que nosotros llamamos pesos **W**) para que los estados que queremos memorizar sean los estados de **m칤nima energ칤a**.

<concept-box>
### El Hamiltoniano de Energ칤a
En una Red de Hopfield, definimos la energ칤a total del sistema como:
<math-block>
  H = -0.5 * Sum( w_ij * s_i * s_j )
</math-block>
Recuperar un recuerdo es simplemente dejar que el sistema evolucione hacia su estado de m칤nima energ칤a (el fondo del valle).
</concept-box>

<Mermaid chart="
graph TD
    A[Estado Inicial Ruidoso] -->|Minimizacion de Energia| B(Valle de Potencial)
    B --> C[Recuerdo Recuperado]
    
    subgraph Paisaje de Energia
    P1[Cima: Alta Energia]
    P2[Valle: Memoria A]
    P3[Valle: Memoria B]
    end
    
    style B fill:#7c3aed20,stroke:#7c3aed
    style Paisaje de Energia fill:rgba(0,212,255,0.05),stroke:#00d4ff
" />

## 3. Atractores y Estabilidad

En f칤sica, un **atractor** es un estado hacia el cual el sistema tiende a evolucionar. 
- Los recuerdos grabados en la matriz de pesos son atractores.
- Si le das a la red un dato incompleto, el sistema "caer치" en el atractor m치s cercano.

Es as칤 de f치cil: aprender es **moldear el paisaje**. Cuando entrenas un modelo, est치s cavando pozos en el mapa de energ칤a para que los datos caigan donde t칰 quieres.

<div className="card bg-slate-900/50 border-[var(--highlight-secondary)]/20 p-6 text-balance">
  <h4 className="text-[var(--highlight-secondary)] mt-0 mb-4">游눠 Perspectiva de Investigador</h4>
  <div className="text-sm m-0 leading-relaxed text-pretty">
    <div>
    Este proceso de minimizaci칩n de energ칤a es lo que permite que las redes neuronales sean robustas al ruido. No importa si a la imagen le faltan p칤xeles; mientras el estado inicial est칠 dentro de la "cuenca de atracci칩n" del recuerdo, la f칤sica se encargar치 de hacer el resto.
    </div>
  </div>
</div>

<CodeBlock
  title="energia_hopfield.py"
  language="python"
  code={`import torch

def calcular_energia(estado, pesos):
    # La energia es E = -0.5 * s.T * W * s
    # Usamos producto matricial para calcularlo de golpe
    energia = -0.5 * torch.dot(estado, pesos @ estado)
    return energia.item()

# Definimos una red con 3 neuronas
W = torch.tensor([[0.0, 1.0, -1.0],
                  [1.0, 0.0, 1.0],
                  [-1.0, 1.0, 0.0]])

estado_valido = torch.tensor([1.0, 1.0, -1.0])
estado_ruidoso = torch.tensor([1.0, -1.0, -1.0])

print(f"Energia del recuerdo: {calcular_energia(estado_valido, W)}")
print(f"Energia con ruido:    {calcular_energia(estado_ruidoso, W)}")
# La energia del recuerdo siempre sera menor!`}
/>
